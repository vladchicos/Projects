Diy neural network with one hidden layer. Comparison between training with Adagrad and Adam optimization algorithms.

The training and testing data can be found here :

https://archive.ics.uci.edu/ml/datasets/Avila#
